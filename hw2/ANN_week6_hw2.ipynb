{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_week6_hw2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Breast Cancer Wisconsin Dataset***\n",
        "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
        "\n",
        "# Dataset\n",
        "---\n",
        "### Classification problem\n",
        "* 10 input variables\n",
        "* 1 **binary** output variable (benign or malignant)\n",
        "\n",
        "### Originally hosted by UCI\n",
        "\n",
        "### 569 data samples\n",
        "* Use the first 100 samples as **test set**\n",
        "* Use the next 100 samples as **validation set**\n",
        "* Use the others as **training set**\n",
        "---\n",
        "# Data PreParation\n",
        "* Remove the rows with missing values \"***?***\"\n",
        "* Load it in the python\n",
        "* Drop the first column : ID\n",
        "* ***Normalize the input variables***\n",
        "* Set the output variable\n",
        "  - Malignant: 1 / benign: 0\n",
        "* Data split: train, test, validation set\n",
        "---\n",
        "# Basic model\n",
        "* Model Structure\n",
        "  - 9 inputs\n",
        "  - 10 hidden neurons / Relu\n",
        "  - 1 output neuron / signoid\n",
        "*Compile and learning condition\n",
        "  - Optimizer = rmsprop\n",
        "  - Loss function = binary crossentropy\n",
        "  - Epochs = 200\n",
        "  - Batch_size = 10\n",
        "  - EarlyStopping with patience = 2"
      ],
      "metadata": {
        "id": "CqnfS4xIL_da"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. **Import models & 데이터 불러오기**\n",
        "\n",
        "\n",
        " **COLUMN 11 (10 in code)=> (2 for benign, 4 for malignant)**"
      ],
      "metadata": {
        "id": "IlvPMTaKQu9A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6KVVa09Ky1_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import models, layers, optimizers, losses, metrics\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/ColabNotebooks/week6/breast-cancer-wisconsin.data\"\n",
        "cancer_origin_data = pd.read_csv(DATA_PATH, delimiter=\",\")\n",
        "cancer_origin_data.columns = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
        "print(cancer_origin_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. **Data preparation**\n",
        "  - Test : 0 ~ 100, Val : 100 ~ 200, Train : 200~\n",
        "  - input : 10 -> 9 (Drop first column / all columns except first one)\n",
        "  - output : 1 (M:4, B:2 => M:1, B:0)\n",
        "  - Normalize (ManMixScaler 사용)"
      ],
      "metadata": {
        "id": "oGie3P5cVlmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop \"?\" rows\n",
        "for label in cancer_origin_data:\n",
        "  for index, data in enumerate(cancer_origin_data.loc[:, label]):\n",
        "      if data == \"?\":\n",
        "        cancer_origin_data = cancer_origin_data.drop(index)\n",
        "# index 재조정\n",
        "cancer_origin_data.index = range(0,len(cancer_origin_data))\n",
        "# output binary 로 변경\n",
        "for index, data in enumerate(cancer_origin_data['10']):\n",
        "  if data == 2:\n",
        "    cancer_origin_data['10'][index] = 0\n",
        "  elif data == 4:\n",
        "    cancer_origin_data['10'][index] = 1\n",
        "# normalization 후 첫번째 열 제거\n",
        "normalization = MinMaxScaler()\n",
        "norm_data = normalization.fit_transform(cancer_origin_data)\n",
        "input_and_output = np.delete(norm_data, 0, axis=1)\n",
        "# input (x), output split (y)\n",
        "x_data = input_and_output[:, 0:9]\n",
        "y_data = input_and_output[:, 9]\n",
        "# train, val, test split\n",
        "# cf) .loc[a:b] => a부터b까지 / [a:b] => a부터b-1까지\n",
        "x_test = x_data[:100, :]\n",
        "y_test = y_data[:100]\n",
        "x_val = x_data[100:200, :]\n",
        "y_val = y_data[100:200]\n",
        "x_train = x_data[200:, :]\n",
        "y_train = y_data[200:]"
      ],
      "metadata": {
        "id": "wxLrQBy7Vlbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. **모델 디자인**\n",
        "  - 9 inputs\n",
        "  - 10 hidden neurons / Relu\n",
        "  - 1 output neuron / sigmoid\n",
        "  - compile\n",
        "    - Optimizer = rmsprop\n",
        "    - Loss function = binary crossentropy"
      ],
      "metadata": {
        "id": "Wovnnv1ZpQW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(10, activation='relu', input_shape=(9, )))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "metadata": {
        "id": "jK3OffHxpQPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. 학습\n",
        "- Epochs = 200\n",
        "- Batch_size = 10\n",
        "- EarlyStopping with patience = 2"
      ],
      "metadata": {
        "id": "fwlezI8QHcTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, epochs=200, batch_size=10,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[EarlyStopping(monitor='val_loss', patience=2)])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"test_loss: \", test_loss, \"test_acc: \", test_acc)"
      ],
      "metadata": {
        "id": "g65O5fDUH1yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extra Question 2\n",
        "\n",
        "get_weights() 를 이용\n"
      ],
      "metadata": {
        "id": "WhFX_BNPfgN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight = model.get_weights()[0]\n",
        "bias = model.get_weights()[1]\n",
        "\n",
        "for i, w in enumerate(weight):\n",
        "  if i > 1 and i < 7:\n",
        "    if i == 2:\n",
        "      print(\".......\")\n",
        "  else:\n",
        "    for j, n in enumerate(w):\n",
        "      if j == len(w) / 2:\n",
        "        print(i, \" input nueron = |===>\", j, \"hidden neuron weight :\", n)\n",
        "      else:\n",
        "        print(\"                  |===>\", j, \"hidden neuron weight :\", n)\n",
        "    print()\n",
        "\n",
        "print(\"+\"*50)\n",
        "for i, b in enumerate(bias):\n",
        "  print(i, \"hidden layer neuron's bias :\", b)"
      ],
      "metadata": {
        "id": "o-5Ea-EWfo4j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}