{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_week6_hw2_Q3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Breast Cancer Wisconsin Dataset***\n",
        "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
        "\n",
        "### Q3 전용 코드"
      ],
      "metadata": {
        "id": "CqnfS4xIL_da"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6KVVa09Ky1_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import models, layers, optimizers, losses, metrics\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/ColabNotebooks/week6/breast-cancer-wisconsin.data\"\n",
        "cancer_origin_data = pd.read_csv(DATA_PATH, delimiter=\",\")\n",
        "cancer_origin_data.columns = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Drop \"?\" rows\n",
        "for label in cancer_origin_data:\n",
        "  for index, data in enumerate(cancer_origin_data.loc[:, label]):\n",
        "      if data == \"?\":\n",
        "        cancer_origin_data = cancer_origin_data.drop(index)\n",
        "# index 재조정\n",
        "cancer_origin_data.index = range(0,len(cancer_origin_data))\n",
        "# output binary 로 변경\n",
        "for index, data in enumerate(cancer_origin_data['10']):\n",
        "  if data == 2:\n",
        "    cancer_origin_data['10'][index] = 0\n",
        "  elif data == 4:\n",
        "    cancer_origin_data['10'][index] = 1\n",
        "# normalization 후 첫번째 열 제거\n",
        "normalization = MinMaxScaler()\n",
        "norm_data = normalization.fit_transform(cancer_origin_data)\n",
        "input_and_output = np.delete(norm_data, 0, axis=1)\n",
        "# input (x), output split (y)\n",
        "x_data = input_and_output[:, 0:9]\n",
        "y_data = input_and_output[:, 9]\n",
        "# train, val, test split\n",
        "# cf) .loc[a:b] => a부터b까지 / [a:b] => a부터b-1까지\n",
        "x_test = x_data[:100, :]\n",
        "y_test = y_data[:100]\n",
        "x_val = x_data[100:200, :]\n",
        "y_val = y_data[100:200]\n",
        "x_train = x_data[200:, :]\n",
        "y_train = y_data[200:]"
      ],
      "metadata": {
        "id": "wxLrQBy7Vlbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. \n",
        "Activation function 이 None, relu, sigmoid, tanh 일 때\n",
        "각각 10번 반복하고 평균과 표준편차를 구하세요. "
      ],
      "metadata": {
        "id": "Wovnnv1ZpQW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hidden layer 의 activation function list\n",
        "hidden_af = [None, 'relu', 'sigmoid', 'tanh']\n",
        "\n",
        "for af in hidden_af:\n",
        "  train_loss = []\n",
        "  train_acc = []\n",
        "  test_loss = []\n",
        "  test_acc = []\n",
        "\n",
        "  for i in range(10):\n",
        "    # 다시 실행한 효과를 얻기위해 모델 초기화\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(10, activation=af, input_shape=(9, )))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
        "                  loss=losses.binary_crossentropy,\n",
        "                  metrics=[metrics.binary_accuracy])\n",
        "\n",
        "    history = model.fit(x_train, y_train, epochs=200, batch_size=10,\n",
        "              validation_data=(x_val, y_val),\n",
        "              callbacks=[EarlyStopping(monitor='val_loss', patience=2)]).history\n",
        "    tl, ta = model.evaluate(x_test, y_test)\n",
        "\n",
        "    # history 의 맨 마지막 값과 evaluate 결과를 각각의 리스트에 추가\n",
        "    train_loss.append(history[\"loss\"][-1])\n",
        "    train_acc.append(history[\"binary_accuracy\"][-1])\n",
        "    test_loss.append(tl)\n",
        "    test_acc.append(ta)\n",
        "    # os.system('clear')\n",
        "  print(str(af))\n",
        "  print(\"mean of\")\n",
        "  print(\"train_loss     train_acc     test_loss     test_acc\")\n",
        "  print(np.average(train_loss), np.average(train_acc), np.average(test_loss), np.average(test_acc))\n",
        "  print(\"=\"*100)\n",
        "  print(\"std of\")\n",
        "  print(\"train_loss     train_acc     test_loss     test_acc\")\n",
        "  print(np.std(train_loss), np.std(train_acc), np.std(test_loss), np.std(test_acc))\n"
      ],
      "metadata": {
        "id": "jK3OffHxpQPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}